{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de363a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in JSONL: 356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'mask': '/data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00534_Study_65512_Series_03.nii.gz',\n",
       "  'body_filled_mask': '/data/usr/yb107/colon_data/refined_by_mobina/Body_filled_all/Patient_00534_Study_65512_Series_03_Body_filled.nii.gz'},\n",
       " {'mask': '/data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00543_Study_02713_Series_03.nii.gz',\n",
       "  'body_filled_mask': '/data/usr/yb107/colon_data/refined_by_mobina/Body_filled_all/Patient_00543_Study_02713_Series_03_Body_filled.nii.gz'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import monai\n",
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai import transforms\n",
    "\n",
    "jsonl_path = \"/home/yb107/cvpr2025/DukeDiffSeg/data/mobina_mixed_colon_dataset/mobina_mixed_colon_dataset_with_body_filled_train.jsonl\"\n",
    "# Load the JSONL file and create a list of dictionaries\n",
    "with open(jsonl_path, \"r\") as f:\n",
    "    files = [json.loads(line) for line in f]\n",
    "print(f\"Number of entries in JSONL: {len(files)}\")\n",
    "file = files[7]\n",
    "file, files[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8764f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import MapTransform\n",
    "\n",
    "\n",
    "class CropForegroundAxisd(MapTransform):\n",
    "    \"\"\"\n",
    "    Crop the tensors in `keys` along a single spatial axis based on the foreground\n",
    "    of `source_key`. Other axes are left untouched.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keys, source_key, axis=0, select_fn=lambda x: x > 0, margin=5):\n",
    "        if not isinstance(keys, (list, tuple)):\n",
    "            keys = [keys]\n",
    "        super().__init__(keys)\n",
    "        if axis not in (0, 1, 2):\n",
    "            raise ValueError(f\"`axis` must be 0, 1, or 2; got {axis}\")\n",
    "        if margin < 0:\n",
    "            raise ValueError(\"`margin` must be >= 0\")\n",
    "        self.keys = list(keys)\n",
    "        self.source_key = source_key\n",
    "        self.axis = axis\n",
    "        self.select_fn = select_fn\n",
    "        self.margin = margin\n",
    "\n",
    "    def _to_tensor(self, x):\n",
    "        return x if isinstance(x, torch.Tensor) else torch.as_tensor(x)\n",
    "\n",
    "    def _get_spatial_axis_index(self, arr_ndim: int) -> int:\n",
    "        if arr_ndim < 3:\n",
    "            raise ValueError(\n",
    "                f\"Input must have at least 3 dims (D,H,W). Got ndim={arr_ndim}\"\n",
    "            )\n",
    "        # spatial dims are the last 3 dims\n",
    "        return arr_ndim - 3 + self.axis\n",
    "\n",
    "    def _compute_crop_indices(self, src):\n",
    "        t = self._to_tensor(src)\n",
    "\n",
    "        # Reduce all non-spatial dims to a 3D spatial volume (D,H,W)\n",
    "        if t.ndim == 3:\n",
    "            spatial = t\n",
    "        else:\n",
    "            n_spatial = 3\n",
    "            reduce_dims = tuple(range(t.ndim - n_spatial))  # e.g., (0,) for C,D,H,W\n",
    "            spatial = t.any(dim=reduce_dims).to(t.dtype)\n",
    "\n",
    "        mask = self.select_fn(spatial)\n",
    "        mask = mask if isinstance(mask, torch.Tensor) else torch.as_tensor(mask)\n",
    "        mask = mask.bool()\n",
    "\n",
    "        if mask.ndim != 3:\n",
    "            raise ValueError(f\"Foreground mask must be 3D; got {tuple(mask.shape)}\")\n",
    "\n",
    "        axis = self.axis\n",
    "        other = tuple(d for d in (0, 1, 2) if d != axis)\n",
    "        # ↓↓↓ fix: reduce both non-axis dims at once to get a 1D presence vector\n",
    "        presence_1d = mask.any(dim=other)\n",
    "\n",
    "        if not presence_1d.any():\n",
    "            return None\n",
    "\n",
    "        idxs = presence_1d.nonzero(as_tuple=False).squeeze(-1)\n",
    "        start = int(idxs.min().item())\n",
    "        end_inclusive = int(idxs.max().item())\n",
    "        size_axis = mask.shape[axis]\n",
    "\n",
    "        start = max(0, start - self.margin)\n",
    "        end = min(size_axis, end_inclusive + 1 + self.margin)  # [start, end)\n",
    "\n",
    "        # Safety: never empty\n",
    "        if end <= start:\n",
    "            center = int((idxs.float().mean().round().item()))\n",
    "            start = max(0, min(center, size_axis - 1))\n",
    "            end = start + 1\n",
    "\n",
    "        return start, end\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "\n",
    "        if self.source_key not in d:\n",
    "            return d\n",
    "\n",
    "        crop_range = self._compute_crop_indices(d[self.source_key])\n",
    "        if crop_range is None:\n",
    "            return d  # nothing to crop\n",
    "\n",
    "        start, end = crop_range\n",
    "\n",
    "        def _safe_crop(arr):\n",
    "            arr_ndim = arr.ndim if hasattr(arr, \"ndim\") else np.asarray(arr).ndim\n",
    "            gaxis = self._get_spatial_axis_index(arr_ndim)\n",
    "            slicers = [slice(None)] * arr_ndim\n",
    "            slicers[gaxis] = slice(start, end)\n",
    "            out = arr[tuple(slicers)]\n",
    "            # --------- NEW: safety net, avoid 0-size dim ----------\n",
    "            if out.shape[gaxis] == 0:\n",
    "                return arr  # fallback to no crop for this key\n",
    "            # ------------------------------------------------------\n",
    "            return out\n",
    "\n",
    "        for key in self.keys:\n",
    "            if key not in d:\n",
    "                continue\n",
    "            d[key] = _safe_crop(d[key])\n",
    "\n",
    "            meta_key = f\"{key}_meta_dict\"\n",
    "            if meta_key in d and isinstance(d[meta_key], dict):\n",
    "                d[meta_key][\"spatial_shape\"] = np.asarray(\n",
    "                    d[key].shape[-3:], dtype=np.int64\n",
    "                )\n",
    "\n",
    "        # Also crop source_key itself if it's not already included\n",
    "        if self.source_key not in self.keys and self.source_key in d:\n",
    "            d[self.source_key] = _safe_crop(d[self.source_key])\n",
    "            meta_key = f\"{self.source_key}_meta_dict\"\n",
    "            if meta_key in d and isinstance(d[meta_key], dict):\n",
    "                d[meta_key][\"spatial_shape\"] = np.asarray(\n",
    "                    d[self.source_key].shape[-3:], dtype=np.int64\n",
    "                )\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "def remove_labels(x: torch.Tensor, labels: list, relabel: bool = False) -> torch.Tensor:\n",
    "    \"\"\"Remove the specified labels from the label tensor.\"\"\"\n",
    "    for label in labels:\n",
    "        x[x == label] = 0\n",
    "\n",
    "    if relabel:\n",
    "        # get unique values in tensor x\n",
    "        unique_values = x.unique()\n",
    "        # Sort the unique values\n",
    "        sorted_uv = sorted(unique_values)\n",
    "        # Remap the labels\n",
    "        for new_label, old_label in enumerate(sorted_uv):\n",
    "            x[x == old_label] = new_label\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transform_labels(x: torch.Tensor, label_map: dict) -> torch.Tensor:\n",
    "    \"\"\"Transform labels in the tensor according to the provided label_map.\"\"\"\n",
    "    label_map_items = label_map.items()\n",
    "    # sort it with old_labels\n",
    "    sorted_items = sorted(label_map_items, key=lambda x: x[0])\n",
    "    for old_label, new_label in sorted_items:\n",
    "        mask = x == old_label\n",
    "        if mask.any():\n",
    "            x[mask] = new_label\n",
    "    return x\n",
    "\n",
    "\n",
    "def dataset_depended_transform_labels(x, kidneys_same_index=False):\n",
    "    \"\"\"\n",
    "    Apply the transform_labels function to the dependent dataset.\n",
    "    Resulting label map:\n",
    "      \"1\": \"colon\",\n",
    "      \"2\": \"rectum\",\n",
    "      \"3\": \"small_bowel\",\n",
    "      \"4\": \"stomach\",\n",
    "      \"5\": \"liver\",\n",
    "      \"6\": \"spleen\",\n",
    "      \"7\": \"kidney_left\",\n",
    "      \"8\": \"kidney_right\",\n",
    "      \"9\": \"pancreas\",\n",
    "      \"10\": \"urinary_bladder\",\n",
    "      \"11\": \"duodenum\",\n",
    "      \"12\": \"gallbladder\",\n",
    "    \"\"\"\n",
    "    pathname = str(x.meta[\"filename_or_obj\"])\n",
    "\n",
    "    if \"colon_refined_by_mobina\" in pathname:\n",
    "        label_map = {\n",
    "            0: 30,\n",
    "            1: 30,\n",
    "            2: 35,\n",
    "            3: 30,\n",
    "            4: 30,\n",
    "            5: 37,\n",
    "            6: 38,\n",
    "            7: 36,\n",
    "            8: 39,\n",
    "            9: 42,\n",
    "            10: 40,\n",
    "            11: 34,\n",
    "            12: 30,\n",
    "            13: 33,\n",
    "            14: 41,\n",
    "            15: 31,\n",
    "            16: 32,\n",
    "            17: 30,\n",
    "        }\n",
    "        x = transform_labels(x, label_map)\n",
    "        x.sub_(30)\n",
    "\n",
    "    elif \"female_cases_refined_by_md\" in pathname:\n",
    "\n",
    "        label_map = {\n",
    "            0: 30,\n",
    "            1: 30,\n",
    "            2: 42,\n",
    "            3: 37,\n",
    "            4: 38,\n",
    "            5: 35,\n",
    "            6: 39,\n",
    "            7: 30,\n",
    "            8: 36,\n",
    "            9: 34,\n",
    "            10: 30,\n",
    "            11: 30,\n",
    "            12: 40,\n",
    "            13: 31,\n",
    "            14: 32,\n",
    "            15: 41,\n",
    "            16: 33,\n",
    "            17: 30,\n",
    "            18: 30,\n",
    "            19: 30,\n",
    "            20: 30,\n",
    "            21: 30,  # uterus\n",
    "            22: 30,  # portal vein and splenic vein\n",
    "            23: 30,  # portal vein and splenic vein\n",
    "            24: 30,  # portal vein and splenic vein\n",
    "        }\n",
    "\n",
    "        x = transform_labels(x, label_map)\n",
    "        x.sub_(30)\n",
    "\n",
    "    elif \"male_cases_refined_by_md\" in pathname:\n",
    "        label_map = {\n",
    "            0: 30,  # background\n",
    "            1: 30,\n",
    "            2: 42,\n",
    "            3: 37,\n",
    "            4: 38,\n",
    "            5: 35,\n",
    "            6: 39,\n",
    "            7: 30,\n",
    "            8: 36,\n",
    "            9: 34,\n",
    "            10: 30,\n",
    "            11: 30,\n",
    "            12: 40,\n",
    "            13: 31,\n",
    "            14: 32,\n",
    "            15: 41,\n",
    "            16: 33,\n",
    "            17: 30,\n",
    "            18: 30,\n",
    "            19: 30,\n",
    "            20: 30,\n",
    "            21: 30,\n",
    "            22: 30,\n",
    "            23: 30,\n",
    "        }\n",
    "        x = transform_labels(x, label_map)\n",
    "        x.sub_(30)\n",
    "\n",
    "    elif (\"a_grade_colons_not_in_refined_by_md\" in pathname) or (\n",
    "        \"c_grade_colons/masks/\" in pathname\n",
    "    ):\n",
    "        label_map = {\n",
    "            13: 0,\n",
    "            14: 0,\n",
    "            15: 0,\n",
    "            16: 0,\n",
    "            17: 0,\n",
    "            18: 0,\n",
    "            19: 0,\n",
    "            20: 0,\n",
    "            21: 0,\n",
    "            22: 0,\n",
    "            23: 0,\n",
    "        }\n",
    "        x = transform_labels(x, label_map)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset for {pathname}\")\n",
    "\n",
    "    if kidneys_same_index:\n",
    "        # Map kidney_right (8) to kidney_left (7)\n",
    "        kidney_merge_map = {8: 7}\n",
    "        x = transform_labels(x, kidney_merge_map)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e55170fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_01799_Study_07874_Series_03.nii.gz, Shape: torch.Size([1, 97, 99, 71])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00370_Study_26660_Series_03.nii.gz, Shape: torch.Size([1, 114, 86, 86])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00862_Study_65668_Series_03.nii.gz, Shape: torch.Size([1, 111, 97, 72])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_02032_Study_41100_Series_03.nii.gz, Shape: torch.Size([1, 112, 100, 73])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_01470_Study_10344_Series_03.nii.gz, Shape: torch.Size([1, 108, 108, 73])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/female_cases_refined_by_md/masks/Patient_02225_Study_60027_Series_03.nii.gz, Shape: torch.Size([1, 97, 79, 80])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00543_Study_02713_Series_03.nii.gz, Shape: torch.Size([1, 97, 99, 70])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00534_Study_65512_Series_03.nii.gz, Shape: torch.Size([1, 112, 100, 94])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00607_Study_31843_Series_03.nii.gz, Shape: torch.Size([1, 100, 109, 106])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00669_Study_70052_Series_03.nii.gz, Shape: torch.Size([1, 121, 112, 77])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00503_Study_36467_Series_03.nii.gz, Shape: torch.Size([1, 110, 104, 75])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00327_Study_16848_Series_03.nii.gz, Shape: torch.Size([1, 126, 98, 85])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00893_Study_55886_Series_03.nii.gz, Shape: torch.Size([1, 105, 67, 77])\n",
      "Shape: torch.Size([1, 95, 94, 49])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/female_cases_refined_by_md/masks/Patient_00431_Study_01401_Series_03.nii.gz, Shape: torch.Size([1, 105, 90, 81])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/female_cases_refined_by_md/masks/Patient_01653_Study_74630_Series_03.nii.gz, Shape: torch.Size([1, 93, 86, 98])\n",
      "Shape: torch.Size([1, 91, 94, 82])\n",
      "Shape: torch.Size([1, 93, 90, 83])\n",
      "Shape: torch.Size([1, 91, 84, 77])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00428_Study_43107_Series_03.nii.gz, Shape: torch.Size([1, 119, 111, 109])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_02193_Study_72321_Series_04_4.1.1.2.3.3.04202.2.1.1.00603517113037506772552007610000.nii.gz, Shape: torch.Size([1, 88, 97, 94])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00058_Study_76664_Series_03.nii.gz, Shape: torch.Size([1, 98, 92, 80])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00032_Study_47243_Series_03.nii.gz, Shape: torch.Size([1, 99, 91, 55])\n",
      "Shape: torch.Size([1, 95, 83, 82])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00277_Study_81402_Series_03.nii.gz, Shape: torch.Size([1, 99, 86, 93])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00713_Study_62082_Series_03.nii.gz, Shape: torch.Size([1, 116, 106, 111])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00647_Study_51380_Series_03.nii.gz, Shape: torch.Size([1, 105, 86, 75])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00051_Study_56111_Series_03.nii.gz, Shape: torch.Size([1, 99, 95, 60])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00017_Study_03180_Series_03.nii.gz, Shape: torch.Size([1, 90, 99, 87])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_01383_Study_76258_Series_03.nii.gz, Shape: torch.Size([1, 112, 103, 73])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00509_Study_57068_Series_03.nii.gz, Shape: torch.Size([1, 102, 96, 80])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_01930_Study_41043_Series_03.nii.gz, Shape: torch.Size([1, 107, 87, 67])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00296_Study_51182_Series_03.nii.gz, Shape: torch.Size([1, 98, 91, 89])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00004_Study_04085_Series_03.nii.gz, Shape: torch.Size([1, 105, 87, 88])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_01555_Study_24545_Series_03.nii.gz, Shape: torch.Size([1, 98, 103, 93])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00926_Study_58517_Series_03_0.8.5.2.3.7.35831.2.1.1.38176501742001782288244230700000.nii.gz, Shape: torch.Size([1, 98, 91, 104])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00731_Study_34146_Series_03.nii.gz, Shape: torch.Size([1, 106, 109, 96])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00580_Study_57252_Series_03.nii.gz, Shape: torch.Size([1, 107, 83, 89])\n",
      "Shape: torch.Size([1, 93, 86, 70])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/male_cases_refined_by_md/masks/Patient_00591_Study_14067_Series_03.nii.gz, Shape: torch.Size([1, 116, 97, 84])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00437_Study_10216_Series_02.nii.gz, Shape: torch.Size([1, 117, 91, 96])\n",
      "Shape: torch.Size([1, 91, 93, 88])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00714_Study_84710_Series_03.nii.gz, Shape: torch.Size([1, 98, 87, 70])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/colon_refined_by_mobina/masks/Patient_00895_Study_77626_Series_03.nii.gz, Shape: torch.Size([1, 103, 90, 89])\n",
      "Shape: torch.Size([1, 87, 84, 75])\n",
      "File: /data/usr/yb107/colon_data/refined_by_mobina/a_grade_colons_not_in_refined_by_md/masks/Patient_00113_Study_84581_Series_03.nii.gz, Shape: torch.Size([1, 97, 94, 82])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# transformed = trans(files[7])\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m---> 69\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtrans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Check its shape, print if any dim is larger than 96\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     mask \u001b[38;5;241m=\u001b[39m transformed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/compose.py:346\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, input_, start, end, threading, lazy)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, threading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, lazy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    345\u001b[0m     _lazy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy \u001b[38;5;28;01mif\u001b[39;00m lazy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lazy\n\u001b[0;32m--> 346\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_compose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/compose.py:116\u001b[0m, in \u001b[0;36mexecute_compose\u001b[0;34m(data, transforms, map_items, unpack_items, start, end, lazy, overrides, threading, log_stats)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threading:\n\u001b[1;32m    115\u001b[0m         _transform \u001b[38;5;241m=\u001b[39m deepcopy(_transform) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_transform, ThreadUnsafe) \u001b[38;5;28;01melse\u001b[39;00m _transform\n\u001b[0;32m--> 116\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_stats\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m data \u001b[38;5;241m=\u001b[39m apply_pending_transforms(data, \u001b[38;5;28;01mNone\u001b[39;00m, overrides, logger_name\u001b[38;5;241m=\u001b[39mlog_stats)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/transform.py:150\u001b[0m, in \u001b[0;36mapply_transform\u001b[0;34m(transform, data, map_items, unpack_items, log_stats, lazy, overrides)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m map_items_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    147\u001b[0m             apply_transform(transform, item, map_items_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, unpack_items, log_stats, lazy, overrides)\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    149\u001b[0m         ]\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# if in debug mode, don't swallow exception so that the breakpoint\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# appears where the exception was raised.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m MONAIEnvVars\u001b[38;5;241m.\u001b[39mdebug():\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/transform.py:98\u001b[0m, in \u001b[0;36m_apply_transform\u001b[0;34m(transform, data, unpack_parameters, lazy, overrides, logger_name)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m unpack_parameters:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m transform(\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transform(data, lazy\u001b[38;5;241m=\u001b[39mlazy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transform, LazyTrait) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/io/dictionary.py:163\u001b[0m, in \u001b[0;36mLoadImaged.__call__\u001b[0;34m(self, data, reader)\u001b[0m\n\u001b[1;32m    161\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(data)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, meta_key, meta_key_postfix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_iterator(d, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta_key_postfix):\n\u001b[0;32m--> 163\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader\u001b[38;5;241m.\u001b[39mimage_only:\n\u001b[1;32m    165\u001b[0m         d[key] \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/transforms/io/array.py:289\u001b[0m, in \u001b[0;36mLoadImage.__call__\u001b[0;34m(self, filename, reader)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot find a suitable reader for file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Please install the reader libraries, see also the installation instructions:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   The current registered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreaders\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m img_array: NdarrayOrTensor\n\u001b[0;32m--> 289\u001b[0m img_array, meta_data \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m img_array \u001b[38;5;241m=\u001b[39m convert_to_dst_type(img_array, dst\u001b[38;5;241m=\u001b[39mimg_array, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(meta_data, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/data/image_reader.py:1123\u001b[0m, in \u001b[0;36mNibabelReader.get_data\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1121\u001b[0m header[MetaKeys\u001b[38;5;241m.\u001b[39mSPATIAL_SHAPE] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_spatial_shape(i)\n\u001b[1;32m   1122\u001b[0m header[MetaKeys\u001b[38;5;241m.\u001b[39mSPACE] \u001b[38;5;241m=\u001b[39m SpaceKeys\u001b[38;5;241m.\u001b[39mRAS\n\u001b[0;32m-> 1123\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_array_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze_non_spatial_dims:\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape), \u001b[38;5;28mlen\u001b[39m(header[MetaKeys\u001b[38;5;241m.\u001b[39mSPATIAL_SHAPE]), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/monai/data/image_reader.py:1217\u001b[0m, in \u001b[0;36mNibabelReader._get_array_data\u001b[0;34m(self, img, filename)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     data_dtype \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mdataobj\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image[data_offset:]\u001b[38;5;241m.\u001b[39mview(data_dtype)\u001b[38;5;241m.\u001b[39mreshape(data_shape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/nibabel/arrayproxy.py:454\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/nibabel/arrayproxy.py:421\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    419\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/nibabel/arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    388\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    401\u001b[0m         fileobj,\n\u001b[1;32m    402\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[1;32m    408\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DukeDiffSeg-HooVw7aP/lib/python3.10/site-packages/nibabel/volumeutils.py:466\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    464\u001b[0m infile\u001b[38;5;241m.\u001b[39mseek(offset)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 466\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mbytearray\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m infile\u001b[38;5;241m.\u001b[39mreadinto(data_bytes)\n\u001b[1;32m    468\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "trans = monai.transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"mask\"]),\n",
    "        # Get same orientation, spacing, and shape\n",
    "        transforms.EnsureChannelFirstd(keys=[\"mask\"]),\n",
    "        transforms.Spacingd(\n",
    "            keys=[\"mask\"],\n",
    "            pixdim=(2, 2, 2),\n",
    "            mode=(\"nearest\"),\n",
    "        ),\n",
    "        transforms.Orientationd(keys=[\"mask\"], axcodes=\"RAS\"),\n",
    "        # transforms.CropForegroundd(\n",
    "        #     keys=[\"mask\", \"body_filled_mask\"], source_key=\"mask\"\n",
    "        # ),\n",
    "        transforms.Lambdad(\n",
    "            keys=[\"mask\"],\n",
    "            func=functools.partial(\n",
    "                dataset_depended_transform_labels,\n",
    "                kidneys_same_index=False,\n",
    "            ),\n",
    "        ),\n",
    "        transforms.Lambdad(\n",
    "            keys=[\"mask\"],\n",
    "            func=functools.partial(\n",
    "                remove_labels,\n",
    "                labels=[\n",
    "                    1,\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                    6,\n",
    "                    7,\n",
    "                    8,\n",
    "                    9,\n",
    "                    10,\n",
    "                    11,\n",
    "                    12,\n",
    "                    13,\n",
    "                    14,\n",
    "                    15,\n",
    "                    16,\n",
    "                    17,\n",
    "                    18,\n",
    "                    19,\n",
    "                    20,\n",
    "                    21,\n",
    "                    22,\n",
    "                ],\n",
    "            ),  # Assuming labels 17 and 14 are the organs,\n",
    "        ),\n",
    "        # CropForegroundAxisd(\n",
    "        #     keys=[\"mask\", \"body_filled_mask\"], source_key=\"mask\", axis=2\n",
    "        # ),\n",
    "        transforms.CropForegroundd(keys=[\"mask\"], source_key=\"mask\"),\n",
    "        # transforms.SaveImaged(\n",
    "        #     keys=[\"mask\"],\n",
    "        #     output_dir=\"tmp\",\n",
    "        #     output_postfix=\"\",\n",
    "        #     separate_folder=False,\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "# transformed = trans(files[7])\n",
    "\n",
    "for file in files:\n",
    "    transformed = trans(file)\n",
    "    # Check its shape, print if any dim is larger than 96\n",
    "    mask = transformed[\"mask\"]\n",
    "    shape = mask.shape\n",
    "    if any(dim > 96 for dim in shape[1:]):\n",
    "        print(f\"File: {file['mask']}, Shape: {shape}\")\n",
    "    else:\n",
    "        print(f\"Shape: {shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DukeDiffSeg-HooVw7aP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
